{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8869092f-9a6c-4a2a-9c28-281f694e0097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting datasets\n",
      "  Using cached datasets-4.3.0-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from datasets) (1.26.4)\n",
      "Collecting pyarrow>=21.0.0 (from datasets)\n",
      "  Using cached pyarrow-22.0.0-cp312-cp312-win_amd64.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\programdata\\anaconda3\\lib\\site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: httpx<1.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from datasets) (0.27.0)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from datasets) (4.66.5)\n",
      "Collecting xxhash (from datasets)\n",
      "  Using cached xxhash-3.6.0-cp312-cp312-win_amd64.whl.metadata (13 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Using cached multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: fsspec<=2025.9.0,>=2023.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2024.6.1)\n",
      "Collecting huggingface-hub<2.0,>=0.25.0 (from datasets)\n",
      "  Using cached huggingface_hub-1.0.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from datasets) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\programdata\\anaconda3\\lib\\site-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (3.10.5)\n",
      "Requirement already satisfied: anyio in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx<1.0.0->datasets) (4.2.0)\n",
      "Requirement already satisfied: certifi in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx<1.0.0->datasets) (2025.7.14)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx<1.0.0->datasets) (1.0.2)\n",
      "Requirement already satisfied: idna in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx<1.0.0->datasets) (3.7)\n",
      "Requirement already satisfied: sniffio in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx<1.0.0->datasets) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\programdata\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.14.0)\n",
      "Requirement already satisfied: shellingham in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (1.5.0)\n",
      "Collecting typer-slim (from huggingface-hub<2.0,>=0.25.0->datasets)\n",
      "  Using cached typer_slim-0.20.0-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (4.11.0)\n",
      "Collecting hf-xet<2.0.0,>=1.2.0 (from huggingface-hub<2.0,>=0.25.0->datasets)\n",
      "  Using cached hf_xet-1.2.0-cp37-abi3-win_amd64.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.11.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from typer-slim->huggingface-hub<2.0,>=0.25.0->datasets) (8.1.7)\n",
      "Using cached datasets-4.3.0-py3-none-any.whl (506 kB)\n",
      "Using cached huggingface_hub-1.0.1-py3-none-any.whl (503 kB)\n",
      "Using cached multiprocess-0.70.16-py312-none-any.whl (146 kB)\n",
      "Using cached pyarrow-22.0.0-cp312-cp312-win_amd64.whl (28.0 MB)\n",
      "Using cached xxhash-3.6.0-cp312-cp312-win_amd64.whl (31 kB)\n",
      "Using cached hf_xet-1.2.0-cp37-abi3-win_amd64.whl (2.9 MB)\n",
      "Using cached typer_slim-0.20.0-py3-none-any.whl (47 kB)\n",
      "Installing collected packages: xxhash, pyarrow, multiprocess, hf-xet, typer-slim, huggingface-hub, datasets\n",
      "Successfully installed datasets-4.3.0 hf-xet-1.2.0 huggingface-hub-1.0.1 multiprocess-0.70.16 pyarrow-22.0.0 typer-slim-0.20.0 xxhash-3.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The scripts hf.exe and tiny-agents.exe are installed in 'C:\\Users\\CSE IIT BHILAI\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script datasets-cli.exe is installed in 'C:\\Users\\CSE IIT BHILAI\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b25e40e-8fb2-482f-8a22-0a4219964efc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6b9c2950801415da2c6c49e7179dab0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/8.88k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CSE IIT BHILAI\\AppData\\Roaming\\Python\\Python312\\site-packages\\huggingface_hub\\file_download.py:120: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\CSE IIT BHILAI\\.cache\\huggingface\\hub\\datasets--lmsys--lmsys-chat-1m. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f16746da1bae4cfbab66e9dc21d3248f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train-00000-of-00006-4feeb3f83346a0(â€¦):   0%|          | 0.00/249M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90a7d4cc72834f55b88f248b0d601392",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train-00001-of-00006-4030672591c2f4(â€¦):   0%|          | 0.00/247M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "687eee6428ad44a2b82a9c9aff2e4a1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train-00002-of-00006-1779b7cec94621(â€¦):   0%|          | 0.00/250M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ceee24d591cb4d3c8be951a4ed3ed494",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train-00003-of-00006-2fa862bfed56af(â€¦):   0%|          | 0.00/247M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc52f2a296d8447d945beece380d2f81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train-00004-of-00006-18f4bdd50c103e(â€¦):   0%|          | 0.00/246M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "190535eb03424938b5c1289d53e2826c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train-00005-of-00006-fe1acc5d10a9f0(â€¦):   0%|          | 0.00/249M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9094d577f544805b288a59a8181beb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1000000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "current_dir=os.getcwd()\n",
    "project_root=os.path.join(current_dir,'..')\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "    \n",
    "from datasets import load_dataset\n",
    "import scripts.prepare_dataset as prep\n",
    "\n",
    "# Login using e.g. `huggingface-cli login` to access this dataset\n",
    "ds = load_dataset(\"lmsys/lmsys-chat-1m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3f08d5-e2cb-4cf5-9bac-7e9ebbd70da1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m remove_indices \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m----> 2\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m train_dataset\u001b[38;5;241m.\u001b[39mselect(\n\u001b[0;32m      3\u001b[0m     [i \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(train_dataset)) \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m remove_indices]\n\u001b[0;32m      4\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_dataset' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c004cb3a-7084-43c2-b9f3-a47ea06a12c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved the 'train' split to: lmsys_chat_1m_train.csv\n"
     ]
    }
   ],
   "source": [
    "train_dataset = ds['train']\n",
    "remove_indices = [1,2]\n",
    "train_dataset = train_dataset.select(\n",
    "    [i for i in range(len(train_dataset)) if i not in remove_indices]\n",
    ")\n",
    "train_dataset=train_dataset.to_pandas()\n",
    "\n",
    "\n",
    "# 3. Save the dataset split to a CSV file\n",
    "output_filepath = \"lmsys_chat_1m_train.csv\"\n",
    "del train_dataset['conversation_id']\n",
    "del train_dataset['model']\n",
    "train_dataset=train_dataset[train_dataset['language']=='English']\n",
    "\n",
    "\n",
    "# The .to_csv() method writes the data to the specified file\n",
    "# You can add arguments like encoding='utf-8' if needed\n",
    "train_dataset.to_csv(output_filepath, index=False)\n",
    "\n",
    "print(f\"Successfully saved the 'train' split to: {output_filepath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec7c8011-15cd-4f00-8f2d-64476d25769a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset: lmsys/lmsys-chat-1m (train split)\n",
      "Loaded 1,000,000 rows. Now splitting into ~100MB chunks...\n",
      "â‰ˆ 18376 rows per CSV\n",
      "Saved at dataset/splits\\lmsys_chat_train_part_1.csv (92.02 MB)\n",
      "Saved at dataset/splits\\lmsys_chat_train_part_2.csv (88.18 MB)\n",
      "Saved at dataset/splits\\lmsys_chat_train_part_3.csv (87.55 MB)\n",
      "Saved at dataset/splits\\lmsys_chat_train_part_4.csv (88.46 MB)\n",
      "Saved at dataset/splits\\lmsys_chat_train_part_5.csv (88.05 MB)\n",
      "Saved at dataset/splits\\lmsys_chat_train_part_6.csv (93.29 MB)\n",
      "Saved at dataset/splits\\lmsys_chat_train_part_7.csv (90.52 MB)\n",
      "Saved at dataset/splits\\lmsys_chat_train_part_8.csv (91.59 MB)\n",
      "Saved at dataset/splits\\lmsys_chat_train_part_9.csv (88.24 MB)\n",
      "Saved at dataset/splits\\lmsys_chat_train_part_10.csv (90.29 MB)\n",
      "Saved at dataset/splits\\lmsys_chat_train_part_11.csv (86.44 MB)\n",
      "Saved at dataset/splits\\lmsys_chat_train_part_12.csv (90.58 MB)\n",
      "Saved at dataset/splits\\lmsys_chat_train_part_13.csv (84.98 MB)\n",
      "Saved at dataset/splits\\lmsys_chat_train_part_14.csv (87.40 MB)\n",
      "Saved at dataset/splits\\lmsys_chat_train_part_15.csv (87.40 MB)\n",
      "Saved at dataset/splits\\lmsys_chat_train_part_16.csv (87.19 MB)\n",
      "Saved at dataset/splits\\lmsys_chat_train_part_17.csv (90.33 MB)\n",
      "Saved at dataset/splits\\lmsys_chat_train_part_18.csv (87.98 MB)\n",
      "Saved at dataset/splits\\lmsys_chat_train_part_19.csv (88.19 MB)\n",
      "Saved at dataset/splits\\lmsys_chat_train_part_20.csv (89.69 MB)\n",
      "Saved at dataset/splits\\lmsys_chat_train_part_21.csv (87.11 MB)\n",
      "Saved at dataset/splits\\lmsys_chat_train_part_22.csv (87.69 MB)\n",
      "Saved at dataset/splits\\lmsys_chat_train_part_23.csv (90.41 MB)\n",
      "Saved at dataset/splits\\lmsys_chat_train_part_24.csv (90.53 MB)\n",
      "Saved at dataset/splits\\lmsys_chat_train_part_25.csv (93.22 MB)\n",
      "Saved at dataset/splits\\lmsys_chat_train_part_26.csv (87.98 MB)\n",
      "Saved at dataset/splits\\lmsys_chat_train_part_27.csv (86.84 MB)\n",
      "Saved at dataset/splits\\lmsys_chat_train_part_28.csv (90.56 MB)\n",
      "Saved at dataset/splits\\lmsys_chat_train_part_29.csv (86.84 MB)\n",
      "Saved at dataset/splits\\lmsys_chat_train_part_30.csv (86.02 MB)\n",
      "Saved at dataset/splits\\lmsys_chat_train_part_31.csv (87.62 MB)\n",
      "Saved at dataset/splits\\lmsys_chat_train_part_32.csv (86.12 MB)\n",
      "Saved at dataset/splits\\lmsys_chat_train_part_33.csv (87.92 MB)\n",
      "Saved at dataset/splits\\lmsys_chat_train_part_34.csv (87.65 MB)\n",
      "Saved at dataset/splits\\lmsys_chat_train_part_35.csv (89.15 MB)\n",
      "Saved at dataset/splits\\lmsys_chat_train_part_36.csv (86.52 MB)\n",
      "Saved at dataset/splits\\lmsys_chat_train_part_37.csv (87.71 MB)\n",
      "Saved at dataset/splits\\lmsys_chat_train_part_38.csv (89.67 MB)\n",
      "Saved at dataset/splits\\lmsys_chat_train_part_39.csv (85.04 MB)\n",
      "Saved at dataset/splits\\lmsys_chat_train_part_40.csv (86.33 MB)\n",
      "Saved at dataset/splits\\lmsys_chat_train_part_41.csv (86.27 MB)\n",
      "Saved at dataset/splits\\lmsys_chat_train_part_42.csv (88.05 MB)\n",
      "Saved at dataset/splits\\lmsys_chat_train_part_43.csv (86.13 MB)\n",
      "Saved at dataset/splits\\lmsys_chat_train_part_44.csv (88.34 MB)\n",
      "Saved at dataset/splits\\lmsys_chat_train_part_45.csv (88.57 MB)\n",
      "Saved at dataset/splits\\lmsys_chat_train_part_46.csv (91.97 MB)\n",
      "Saved at dataset/splits\\lmsys_chat_train_part_47.csv (87.33 MB)\n",
      "Saved at dataset/splits\\lmsys_chat_train_part_48.csv (89.67 MB)\n",
      "Saved at dataset/splits\\lmsys_chat_train_part_49.csv (96.68 MB)\n",
      "Saved at dataset/splits\\lmsys_chat_train_part_50.csv (87.96 MB)\n",
      "Saved at dataset/splits\\lmsys_chat_train_part_51.csv (85.94 MB)\n",
      "Saved at dataset/splits\\lmsys_chat_train_part_52.csv (87.76 MB)\n",
      "Saved at dataset/splits\\lmsys_chat_train_part_53.csv (85.54 MB)\n",
      "Saved at dataset/splits\\lmsys_chat_train_part_54.csv (95.64 MB)\n",
      "Saved at dataset/splits\\lmsys_chat_train_part_55.csv (36.83 MB)\n",
      "All splits saved successfully under: dataset/splits\n"
     ]
    }
   ],
   "source": [
    "prep.split_and_save_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332e3e18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16235f75-ff85-485d-9009-5868ae6f45e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "for i in range(1,56):\n",
    "    dfi=pd.read_csv(f'dataset/splits/lmsys_chat_train_part_{i}.csv')\n",
    "    dfi.to_csv(f'dataset/splits/lmsys_chat_train_part_{i}.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78de1f44-6f13-4b9f-a85e-bcd259cc7193",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375755dc-8972-4d2d-90c0-63f86a95b3c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
